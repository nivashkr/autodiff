{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df32c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii nivash\n"
     ]
    }
   ],
   "source": [
    "print(\"hii nivash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a4636",
   "metadata": {},
   "source": [
    "#froward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5156fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class value:\n",
    "    def __init__(self, data, children = (), op = ''):\n",
    "        self.data = data\n",
    "        self.op = op\n",
    "        self.prev = set(children)\n",
    "        self._backward = lambda : None\n",
    "        self.grad = 0.0\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        # return f\"value is :{self.data}  gradient is : {self.grad} operation is :  {self.op} previous values: {self.prev}\\n backward function : {self.backward}\\n\"\n",
    "        return f\"value(data = {self.data} grad = {self.grad})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, value):\n",
    "            other = value(other)\n",
    "            \n",
    "            \n",
    "        result = value(self.data + other.data, (self, other), '+')\n",
    "        def grad_calculator():\n",
    "            self.grad += result.grad\n",
    "            other.grad += result.grad\n",
    "        result._backward = grad_calculator \n",
    "        return result\n",
    "    \n",
    "    # def __radd__(self, other):\n",
    "    #     return self + other\n",
    "    \n",
    "    \n",
    "    def __neg__(self):\n",
    "        \n",
    "        return self * -1\n",
    "    \n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self + (-other)\n",
    "        \n",
    "        \n",
    "    def __pow__(self, other):\n",
    "            \n",
    "        assert isinstance(other, int | float)\n",
    "            \n",
    "        result = value(self.data**other, (self,), f'{other}')\n",
    "        def grad_calculator():\n",
    "            self.grad += other * (self.data** (other - 1)) * result.grad\n",
    "            \n",
    "        result._backward = grad_calculator\n",
    "        return result\n",
    "        \n",
    "    def __truediv__(self, other):\n",
    "        return self * (other ** -1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if not isinstance(other, value):\n",
    "            other = value(other)\n",
    "            \n",
    "        result = value(self.data * other.data, (self, other) , '*')\n",
    "        def grad_calculator():\n",
    "            self.grad += result.grad * other.data\n",
    "            other.grad += result.grad * self.data\n",
    "        result._backward = grad_calculator\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # def __rmul__(self, other):\n",
    "    #     return self * other\n",
    "    \n",
    "    def exp(self):\n",
    "        result = value(math.exp(self.data), (self,), 'exp')\n",
    "        def grad_calculator():\n",
    "            self.grad += result.grad * math.exp(self.data)\n",
    "        result._backward = grad_calculator\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def tanh(self):\n",
    "        n = self.data\n",
    "        out = (math.exp(2.0*n) - 1)/(math.exp(2.0*n) + 1)\n",
    "        result = value(out, (self,), 'tanh')\n",
    "        def grad_calculator():\n",
    "            self.grad += (1 - out**2) * result.grad\n",
    "            \n",
    "            \n",
    "        result._backward = grad_calculator\n",
    "            \n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v.prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "            \n",
    "        build_topo(self)\n",
    "        topo.reverse()\n",
    "        self.grad = 1.0\n",
    "        \n",
    "        \n",
    "        for x in topo:\n",
    "            x._backward()\n",
    "            \n",
    "    __radd__ = __add__\n",
    "    __rmul__ = __mul__\n",
    "            \n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305b95a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value(data = 12.0 grad = 0.0) value(data = 18.0 grad = 0.0) value(data = 81.0 grad = 0.0) value(data = 1.5 grad = 0.0) value(data = 6.0 grad = 0.0) value(data = 12.0 grad = 0.0)\n"
     ]
    }
   ],
   "source": [
    "x = value(3.0)\n",
    "y = value(4.0)\n",
    "\n",
    "\n",
    "print(y*3, 4.5*y, x**4,  x/2, 3 + x, x + 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1adcc31",
   "metadata": {},
   "source": [
    "#direct tanh usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6ce43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is :  value(data = 0.4 grad = -0.08811156691047467) \n",
      "b is :  value(data = 0.8 grad = -0.044055783455237335) \n",
      "c is : value(data = 1.0 grad = -0.11013945863809332) \n",
      "d is :  value(data = 1.32 grad = -0.11013945863809332) \n",
      "e is :  value(data = 0.32000000000000006 grad = -0.11013945863809332) \n",
      "f is :  value(data = -1.5 grad = 0.09692272360152213) \n",
      "l is :  value(data = -1.98 grad = 0.07342630575872888) \n",
      "o is :  value(data = -0.9625869800912908 grad = 1.0)\n"
     ]
    }
   ],
   "source": [
    "a = value(0.4)\n",
    "b= value(0.8)\n",
    "e= a*b\n",
    "c = value(1.0)\n",
    "d = c+e\n",
    "f = value(-1.5)\n",
    "l = d*f\n",
    "o = l.tanh()\n",
    "\n",
    "o.backward()\n",
    "\n",
    "print(\"a is : \" ,a, \"\\nb is : \",b, \"\\nc is :\",c, \"\\nd is : \",d, \"\\ne is : \",e, \"\\nf is : \",f,\"\\nl is : \",l, \"\\no is : \", o )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da6c98",
   "metadata": {},
   "source": [
    "#indirect tanh usage using chunck functions to check whether the chunking is done correctly or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737c9141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is :  value(data = 0.4 grad = -0.08811156691047475) \n",
      "b is :  value(data = 0.8 grad = -0.04405578345523738) \n",
      "c is : value(data = 1.0 grad = -0.11013945863809343) \n",
      "d is :  value(data = 1.32 grad = -0.11013945863809343) \n",
      "e is :  value(data = 0.32000000000000006 grad = -0.11013945863809343) \n",
      "f is :  value(data = -1.5 grad = 0.09692272360152222) \n",
      "l is :  value(data = -1.98 grad = 0.07342630575872895) \n",
      "o is :  value(data = -0.9625869800912908 grad = 1.0)\n"
     ]
    }
   ],
   "source": [
    "a = value(0.4)\n",
    "b= value(0.8)\n",
    "e= a*b\n",
    "c = value(1.0)\n",
    "d = c+e\n",
    "f = value(-1.5)\n",
    "l = d*f\n",
    "\n",
    "m = 2*l\n",
    "n = m.exp()\n",
    "\n",
    "o = (n-1)/(n+1)\n",
    "\n",
    "o.backward()\n",
    "\n",
    "print(\"a is : \" ,a, \"\\nb is : \",b, \"\\nc is :\",c, \"\\nd is : \",d, \"\\ne is : \",e, \"\\nf is : \",f,\"\\nl is : \",l, \"\\no is : \", o )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1277e11",
   "metadata": {},
   "source": [
    "#using pytorch to implement the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc9bfe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is : 0.4000000059604645 , a.grad is : -0.08811157196760178 \n",
      "b is : 0.800000011920929 , b.grad is : -0.04405578598380089 \n",
      "c is : 1.0 , c.grad is : -0.11013945937156677 \n",
      "d is : 1.3200000524520874 , d.grad is : -0.11013945937156677 \n",
      "e is : 0.320000022649765 , e.grad is : -0.11013945937156677 \n",
      "f is : -1.5 , f.grad is : 0.09692272543907166 \n",
      "l is : -1.9800000190734863 , l.grad is : 0.07342630624771118 \n",
      "o is : -0.9625869989395142 , o.grad is : 1.0 \n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "\n",
    "a = t.tensor(0.4, requires_grad = True)\n",
    "b= t.tensor(0.8, requires_grad = True)\n",
    "e= a*b\n",
    "c = t.tensor(1.0, requires_grad = True)\n",
    "d = c+e\n",
    "f = t.tensor(-1.5, requires_grad = True)\n",
    "l = d*f\n",
    "\n",
    "\n",
    "\n",
    "m = 2*l\n",
    "n = m.exp()\n",
    "\n",
    "\n",
    "o = (n-1)/(n+1)\n",
    "\n",
    "d.retain_grad()\n",
    "e.retain_grad()\n",
    "l.retain_grad()\n",
    "o.retain_grad()\n",
    "o.backward()\n",
    "\n",
    "\n",
    "# print(\"a : \" , a.item(), a.grad , \"\\nb is : \",b.item() , b.grad,  \"\\nc is :\",c, \"\\nd is : \",d, \"\\ne is : \",e, \"\\nf is : \",f,\"\\nl is : \",l, \"\\no is : \", o )\n",
    "\n",
    "mydict = {'a': a , 'b': b, 'c': c, 'd': d, 'e' : e , 'f' : f, 'l' : l, 'o' : o}\n",
    "\n",
    "\n",
    "for key in mydict:\n",
    "    print(f\"{key} is : {mydict[key]} , {key}.grad is : {mydict[key].grad} \")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodiff-engine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
